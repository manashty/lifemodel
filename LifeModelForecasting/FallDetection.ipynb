{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_version='2.6'\n",
    "date='March 8th, 2018, UNB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened input file and ready for reading from FallDataAvgFixed32AutoShift_50Miss_2018-03-10  15-17-39.csv\n",
      "Read output samples: 126 samples from FallDataAvgFixed32AutoShift_50Miss_2018-03-10  15-17-39.csv\n",
      "Y length:\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "from ReadBatchZipLM_Omit_Accel_Readdata_reg import Y, batch_read_thread, reset, method, filename, omit, reg, input_file_variable_name, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE CPU ONLY\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"#'-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score, roc_curve, f1_score, classification_report, recall_score, brier_score_loss, precision_score, regression\n",
    "    \n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "from keras import metrics\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow\n",
    "import threading\n",
    "import queue\n",
    "import pickle\n",
    "import jsonpickle\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epoch(object):\n",
    "    def __init__(self, e, **kwargs):\n",
    "        self.number=e\n",
    "        self.data=dict()\n",
    "        self.input_output=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "L1_LSTM (LSTM)               (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "Output_Dense_reg (Dense)     (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,769\n",
      "Trainable params: 4,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, input_shape=(32,4), name=\"L1_LSTM\"))\n",
    "\n",
    "if(not reg):\n",
    "    if(not omit):\n",
    "        output_layer=1\n",
    "        model.add(Dense(output_layer, activation='sigmoid', name=\"Output_Dense\"))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])   \n",
    "    else:\n",
    "        #output_layer=4\n",
    "        output_layer=1\n",
    "        model.add(Dense(output_layer, activation='sigmoid', name=\"Output_Dense\"))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "else:\n",
    "    output_layer=1\n",
    "    model.add(Dense(output_layer, name=\"Output_Dense_reg\"))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "print((model.summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "#fill it according to dataset file\n",
    "n_samples = 453\n",
    "\n",
    "if(not reg):\n",
    "    totalSamples,minibatchSize,testPercentage, epochs, minibatch_epochs=(n_samples,n_samples,0.1,n_epochs,10)\n",
    "else:\n",
    "    totalSamples,minibatchSize,testPercentage, epochs, minibatch_epochs=(n_samples,n_samples,0.2,n_epochs,10)\n",
    "    \n",
    "no_mini_batches=int(totalSamples/minibatchSize)\n",
    "X_test_all=[]\n",
    "y_test_all=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(totalSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dateformatFile='%Y-%m-%d  %H-%M-%S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results 2018-03-12  21-06-41 Samples-126_MB-126_TestPerc20_reg_Fixed32AutoShift\n"
     ]
    }
   ],
   "source": [
    "directory=\"Results \"+str(datetime.datetime.now().strftime(dateformatFile))+' Samples-{0}_MB-{1}_TestPerc{2}_{3}'.format(totalSamples,minibatchSize, int(testPercentage*100),method)\n",
    "print(directory)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename= FallDataAvgLifeModel32Input.csv\n",
    "\n",
    "#An empty file with the name of the input file!\n",
    "#mehrdad(why commented?)\n",
    "#open(directory+'/'+filename.format(\"Input\"),'wb').close()\n",
    "logFile=open(directory+'/'+'log.txt','wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*\tScript version: 2.6\n",
      "*\tLog file created at 2018/03/12  21:06:41\n",
      "*\tDirectory: Results 2018-03-12  21-06-41 Samples-126_MB-126_TestPerc20_reg_Fixed32AutoShift\n",
      "*\tFilename Template: FallDataAvgFixed32AutoShift{0}_2018-03-10  15-17-39.csv\n",
      "*\tFilename Input: FallDataAvgFixed32AutoShift_50Miss_2018-03-10  15-17-39.csv\n",
      "*\tFilename Output: FallDataAvgFixed32AutoShift_50MissOutput_2018-03-10  15-17-39.csv\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(filename=directory+'/'+'log.txt',format='%(message)s', level=logging.DEBUG)\n",
    "#Adding log to console as well\n",
    "consoleHandler=logging.StreamHandler()\n",
    "consoleHandler.setFormatter(logging.Formatter('*\\t%(message)s'))\n",
    "logging.getLogger().addHandler(consoleHandler)\n",
    "dateformat=\"%Y/%m/%d  %H:%M:%S\"\n",
    "logging.info(\"Script version: \"+script_version)\n",
    "logging.info(\"Log file created at \"+datetime.datetime.now().strftime(\"%Y/%m/%d  %H:%M:%S\"))\n",
    "logging.info(\"Directory: {0}\".format(directory))\n",
    "logging.info(\"Filename Template: {0}\".format(filename))\n",
    "logging.info(\"Filename Input: {0}\".format(filename.format(input_file_variable_name)))\n",
    "logging.info(\"Filename Output: {0}\".format(filename.format(input_file_variable_name + \"Output\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=directory, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*\tStart time: 2018-03-12 21:06:47.025518\n",
      "*\tNone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "L1_LSTM (LSTM)               (None, 32)                4736      \n",
      "_________________________________________________________________\n",
      "Output_Dense_reg (Dense)     (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,769\n",
      "Trainable params: 4,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "startTime=datetime.datetime.now()\n",
    "logging.info('Start time: '+str(startTime))    \n",
    "logging.info((model.summary()))\n",
    "accuracy=[]\n",
    "\n",
    "metricsReports=[]\n",
    "q=queue.Queue(1)\n",
    "epochsData=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3]\n",
      "<function batch_read_thread at 0x00000246B39BF268>\n",
      "<function reset at 0x00000246B39BF1E0>\n",
      "reg_Fixed32AutoShift\n",
      "FallDataAvgFixed32AutoShiftInput_2018-03-10  15-17-39.csv\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(Y, batch_read_thread, reset, method, filename.format(\"Input\"), omit,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*\t\t##########################################################################\n",
      "*\t\t############# Epoch 1 started @ 2018/03/12  21:06:51 ####################\n",
      "*\t\t##########################################################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *******I/O(1/126->1)***\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*\t*********Epoch 1 of 10, Minibatch 1 of 1 @ 2018/03/12  21:06:51********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *******I/O(3/126->3)***\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*\tSamples:126, reg_Fixed32AutoShift, MBatch: 126, Test 0.2, Total 25, MB:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Finished Reading 126 from 0 to 126 Samples***\n",
      "X=X2\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-fe3fe1c6a054>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mte\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtestPercentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Rand 10 percent for testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mtr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#The remaining 90 percent for training\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "\n",
    "    epoch_start_time=datetime.datetime.now()\n",
    "    logging.info(\"\\t##########################################################################\")\n",
    "    logging.info(\"\\t############# Epoch {0} started @ {1} ####################\".format(e+1,str(epoch_start_time.strftime(dateformat))))\n",
    "    logging.info(\"\\t##########################################################################\")\n",
    "    \n",
    "    epoch=Epoch(e)\n",
    "    \n",
    "    X_test_all=[]\n",
    "    y_test_all=[]\n",
    "    X2=[] \n",
    "    if e==0:#No need for reseting the file if it is not the first minibatch\n",
    "        #print(\"Reading Thread Starting (Epoch Thread)\")\n",
    "        reset()\n",
    "        readingThread=threading.Thread(target=batch_read_thread,args=(q,minibatchSize))\n",
    "        readingThread.start()\n",
    "        \n",
    "    if e>0:#Should not be necessary anymore\n",
    "        readingThread.join()\n",
    "    \n",
    "    batch_data=[]\n",
    "    epoch.input_output['all_batches_training_history_loss']=[]\n",
    "    epoch.input_output['all_batches_training_history_accuracy']=[]\n",
    "    epoch.input_output['all_batches_training_history_mse']=[]\n",
    "    \n",
    "    for minibatch in range(no_mini_batches):\n",
    "        #Read samples and prepare data\n",
    "        minibatch_start_time=datetime.datetime.now()\n",
    "        logging.info(\"*********Epoch {2} of {3}, Minibatch {0} of {1} @ {4}********\".format(minibatch+1,no_mini_batches,e+1,epochs,str(minibatch_start_time.strftime(dateformat))))\n",
    "        logging.info(\"Samples:{0}, {3}, MBatch: {1}, Test {2}, Total {4}, MB:{5}\".format(totalSamples,minibatchSize,testPercentage,method, int(testPercentage*totalSamples),int(testPercentage*minibatchSize)))\n",
    "      \n",
    "        #readingThread.start()        \n",
    "        readingThread.join()        \n",
    "        #print(\"Finished!\")                \n",
    "        X2=q.get()\n",
    "        #print('Len X2:')\n",
    "        #print(len(X2))\n",
    "        #len(X2)\n",
    "        X=X2\n",
    "        \n",
    "        print(\"X=X2\")\n",
    "        print(len(X2))\n",
    "        \n",
    "        te=list(numpy.random.randint(0,len(X),size=int((len(X)*testPercentage))))#Rand 10 percent for testing\n",
    "        tr=set(list(range(0,len(X))))-set(te)#The remaining 90 percent for training\n",
    "        \n",
    "        offset=minibatchSize*minibatch\n",
    "        \n",
    "        X_train=[X[i] for i in tr]\n",
    "        y_train=[Y[offset+i] for i in tr]\n",
    "        X_test=[X[i] for i in te]\n",
    "        y_test=[Y[offset+i] for i in te]\n",
    "        X_test_all.extend(X_test)\n",
    "        y_test_all.extend(y_test)\n",
    "        \n",
    "        if(minibatch==(no_mini_batches-1)):#If last minibatch, reset to read the first batch for next epoch\n",
    "            reset()\n",
    "\n",
    "        readingThread=threading.Thread(target=batch_read_thread,args=(q,minibatchSize))\n",
    "        readingThread.start()\n",
    "        \n",
    "        history=model.fit(numpy.array(X_train), numpy.array(y_train),\n",
    "                          epochs=minibatch_epochs, batch_size=1,\n",
    "                          callbacks=[tensorboard])\n",
    "        logging.info(\"Batch History: \")\n",
    "        logging.info(str(history.history.items()))\n",
    "        \n",
    "        scores = model.evaluate(numpy.array(X_test), numpy.array(y_test))#, verbose=0)\n",
    "        epoch.input_output['all_batches_training_history_loss'].append((history.history['loss']))\n",
    "        if(not reg):\n",
    "            epoch.input_output['all_batches_training_history_accuracy'].append(history.history['acc'])\n",
    "            logging.info(\"Test Accuracy: %.3f%%\" % (scores[1]*100))\n",
    "            \n",
    "        else:\n",
    "            epoch.input_output['all_batches_training_history_accuracy'].append(history.history['mean_squared_error'])\n",
    "            logging.info(\"Test MSE: %.3f%%\" % (scores[1]*100))\n",
    "    \n",
    "        \n",
    "        logging.info(\"**END****Epoch {2} of {3}, Minibatch {0} of {1} in {4} ********\".format(minibatch+1,no_mini_batches,e+1,epochs,str((datetime.datetime.now()-minibatch_start_time))))\n",
    "        logging.info('')\n",
    "        \n",
    "    # Final evaluation of the model    \n",
    "    logging.info(\"For {0} test samples\".format(len(y_test_all)))\n",
    "    logging.info(\"True Values\")\n",
    "    logging.info(y_test_all)\n",
    "    logging.info(\"Predicted Values\")\n",
    "    result=model.predict_on_batch(numpy.array(X_test_all))\n",
    "    logging.info(model.predict_on_batch(numpy.array(X_test_all)))\n",
    "    logging.info(\"Comparison on all:\")\n",
    "    result_both=[(float(result[i]),round(float(result[i])), y_test_all[i]) for i in range(len(result))]\n",
    "    if(not omit):\n",
    "        y_score=[round(float(y)) for y in result]\n",
    "    else:\n",
    "        y_score=result\n",
    "            \n",
    "    scores = model.evaluate(numpy.array(X_test_all), numpy.array(y_test_all), verbose=0)\n",
    "    accuracy.append((scores[1]*100, scores[0]))\n",
    "    \n",
    "    epoch.data['accuracy']=scores[1]\n",
    "    epoch.data['loss']=scores[0]\n",
    "        \n",
    "    if(not omit):\n",
    "        if(not reg):\n",
    "            epoch.data['average_precision']=average_precision_score(y_test_all, y_score)\n",
    "            #Mehrdad. I commented the line below because when all of 7 test samples are 1, it causes an error.\n",
    "            #https://stackoverflow.com/questions/39018097/sklearn-auc-valueerror-only-one-class-present-in-y-true\n",
    "            #epoch.data['roc_auc']=roc_auc_score(y_test_all, y_score)\n",
    "            epoch.input_output['roc_curve']=roc_curve(y_test_all, y_score)\n",
    "            epoch.data['f1']=f1_score(y_test_all, y_score)\n",
    "            epoch.data['recall']=recall_score(y_test_all, y_score)\n",
    "            epoch.data['precision']=precision_score(y_test_all, y_score)\n",
    "        \n",
    "        if(not reg):\n",
    "            #Calculate Brier Score\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                prob_pos = model.predict_proba(numpy.array(X_test_all))#[:, 1]\n",
    "            else:  # use decision function\n",
    "                prob_pos = model.decision_function(numpy.array(X_test_all))\n",
    "                prob_pos = \\\n",
    "                        (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "\n",
    "            epoch.input_output['prob_pos']=prob_pos\n",
    "\n",
    "            epoch.input_output['Y_test_all']=y_test_all\n",
    "            epoch.input_output['y_predictions']=y_score\n",
    "\n",
    "            clf_score = brier_score_loss(y_test_all, prob_pos, pos_label=1)\n",
    "            brier=clf_score \n",
    "\n",
    "            epoch.data['brier']=clf_score\n",
    "\n",
    "            logging.info('Brier: {0:0.2f}'.format(clf_score))\n",
    "\n",
    "    \n",
    "\n",
    "        #print(':')\n",
    "        epoch.input_output['classification_report']=classification_report(y_test_all, y_score)\n",
    "        metricsReports.append(epoch.input_output['classification_report'])\n",
    "        \n",
    "    epochsData.append(epoch)\n",
    "    \n",
    "\n",
    "    logging.info(result_both)\n",
    "    logging.info(\"Predictions on all:\")\n",
    "    \n",
    "    logging.info(\"\")\n",
    "    logging.info(\"*****************************************\")\n",
    "    logging.info(\"***Epoch Summary***\")\n",
    "    logging.info(\"Parameters: Samples:{0}, Minibatch Size: {1}, Test ratio: {2} \".format(totalSamples,minibatchSize,testPercentage))    \n",
    "    logging.info(str(epoch.data))\n",
    "    logging.info(\"Loss: %.2f%%\" % (scores[0]))\n",
    "    \n",
    "    if(not omit):\n",
    "        if(not reg):\n",
    "            logging.info('Average precision-recall: {0:0.2f}'.format(epoch.data['average_precision']))\n",
    "        #mehrdad\n",
    "        #logging.info('AU-ROC: {0:0.2f}'.format(epoch.data['roc_auc']))   \n",
    "            logging.info('F1: {0:0.2f}'.format(epoch.data['f1']))    \n",
    "            logging.info('Recall: {0:0.2f}'.format(epoch.data['recall']))\n",
    "            logging.info('Precision: {0:0.2f}'.format(epoch.data['precision']))\n",
    "            logging.info(\"Accuracy: %.2f%%\" % (scores[1]*100))    \n",
    "            logging.info(\"Brier: %.2f%%\" % (brier))    \n",
    "            logging.info(\"*****************************************\")\n",
    "            logging.info(\"***Classification Reports***\")\n",
    "    \n",
    "    if(not reg):\n",
    "        for ep in range(e+1):\n",
    "            logging.info(\"Epoch {0} accuracy:{1}, loss:{2}\".format(ep+1,accuracy[ep][0],accuracy[ep][1]))\n",
    "            if(not omit):\n",
    "                logging.info(metricsReports[ep])\n",
    "    \n",
    "    #print(\"***Metrics***\")\n",
    "    logging.info(\"***Metrics***\")\n",
    "    for ep in range(e+1):\n",
    "        if (not reg):\n",
    "            logging.info(\"Epoch {0} accuracy:{1}, loss:{2}\".format(ep+1,accuracy[ep][0],accuracy[ep][1]))\n",
    "        else:\n",
    "            logging.info(\"Epoch {0} MSE:{1}, loss:{2}\".format(ep+1,accuracy[ep][0],accuracy[ep][1]))\n",
    "        \n",
    "        #print(\"Epoch {0} metrics\".format(ep+1))        \n",
    "        logging.info(epochsData[ep].data)\n",
    "\n",
    "        #print([str(met) for met in metricsAll[e]])\n",
    "    logging.info(\"***Results***\")\n",
    "    \n",
    "    if(not reg):\n",
    "        for ep in range(e+1):\n",
    "            logging.info(\"Epoch {0} Accuracy:{1}, Loss:{2}\".format(ep+1,accuracy[ep][0],accuracy[ep][1]))\n",
    "    else:\n",
    "        for ep in range(e+1):\n",
    "            logging.info(\"Epoch {0} MSE:{1}, Loss:{2}\".format(ep+1,accuracy[ep][0],accuracy[ep][1]))\n",
    "        \n",
    "    logging.info(\"Parameters: Samples:{0}, Method={3}, Minibatch Size: {1}, Test: Ratio: {2}, Total {4}, MB:{5}\".format(totalSamples,minibatchSize,testPercentage, method, int(testPercentage*totalSamples),int(testPercentage*minibatchSize)))\n",
    "    if(not reg):\n",
    "        logging.info(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    else:\n",
    "        logging.info(\"MSE: %.2f%%\" % (scores[1]*100))\n",
    "    \n",
    "    logging.info(\"***END OF EPOCH {0} of {1}** @ {2} in {3}*\".format(e+1, epochs,datetime.datetime.now().strftime(dateformat),str((datetime.datetime.now()-epoch_start_time))))\n",
    "    logging.info(\"*****************************************\")\n",
    "    logging.info(\"\")\n",
    "    \n",
    "    acc_train=[epoch_iter.input_output['all_batches_training_history_accuracy'][-1][-1] for epoch_iter in epochsData]\n",
    "    loss_train=[epoch_iter.input_output['all_batches_training_history_loss'][-1][-1] for epoch_iter in epochsData]\n",
    "\n",
    "    acc=[epoch_iter.data['accuracy'] for epoch_iter in epochsData]\n",
    "    loss=[epoch_iter.data['loss'] for epoch_iter in epochsData]\n",
    "\n",
    "    plt.plot(acc_train)\n",
    "    plt.plot(acc)\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory+'/Accuracy'+str(e+1)+'.pdf',bbox_inches='tight', pad_inches=0)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(loss_train)\n",
    "    plt.plot(loss)\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    #plt.show()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory+'/Loss'+str(e+1)+'.pdf',bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "    if(not reg):\n",
    "        #Plot Brier\n",
    "        if(not omit):\n",
    "            fig = plt.figure(1, figsize=(10, 10))\n",
    "            ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "            ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "            ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "            fraction_of_positives, mean_predicted_value = \\\n",
    "                    calibration_curve(y_test_all, prob_pos, n_bins=10)\n",
    "\n",
    "            epoch.input_output['fraction_of_positives']=fraction_of_positives\n",
    "            epoch.input_output['mean_predicted_value']=mean_predicted_value \n",
    "\n",
    "\n",
    "            ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "                         label=\"%s (%1.3f)\" % ('Model', clf_score))\n",
    "\n",
    "            ax2.hist(prob_pos, range=(0, 1), bins=10, label='LSTM',\n",
    "                         histtype=\"step\", lw=2)\n",
    "\n",
    "            ax1.set_ylabel(\"Fraction of positives\")\n",
    "            ax1.set_xlabel(\"Mean predicted value\")\n",
    "\n",
    "            ax1.set_ylim([-0.05, 1.05])\n",
    "            ax1.legend(loc=\"lower right\")\n",
    "            ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "            ax2.set_xlabel(\"Mean predicted value\")\n",
    "            ax2.set_ylabel(\"Count\")\n",
    "            ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(directory+'/Calibration Epoch '+str(e+1)+'.pdf',bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "            #plt.show()\n",
    "\n",
    "            #Plot Brier for all\n",
    "\n",
    "                #Plot Brier\n",
    "\n",
    "\n",
    "            fig = plt.figure(1, figsize=(10, 10))\n",
    "            ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "            ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "            ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "            fraction_of_positives, mean_predicted_value = \\\n",
    "                    calibration_curve(y_test_all, prob_pos, n_bins=10)\n",
    "\n",
    "            epoch.input_output['fraction_of_positives']=fraction_of_positives\n",
    "            epoch.input_output['mean_predicted_value']=mean_predicted_value \n",
    "\n",
    "\n",
    "            for x in epochsData:\n",
    "                ax1.plot(x.input_output['mean_predicted_value'], x.input_output['fraction_of_positives'], \"s-\",\n",
    "                        label=\"%s (%1.3f)\" % ('Epoch{0}'.format(str(x.number+1)), x.data['brier']))\n",
    "\n",
    "            #ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             #            label=\"%s (%1.3f)\" % ('LSTM', clf_score))\n",
    "\n",
    "            ax2.hist(prob_pos, range=(0, 1), bins=10, label='LSTM',\n",
    "                         histtype=\"step\", lw=2)\n",
    "\n",
    "            ax1.set_ylabel(\"Fraction of positives\")\n",
    "            ax1.set_xlabel(\"Mean predicted value\")\n",
    "\n",
    "            ax1.set_ylim([-0.05, 1.05])\n",
    "            ax1.legend(loc=\"lower right\")\n",
    "            ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "            ax2.set_xlabel(\"Mean predicted value\")\n",
    "            ax2.set_ylabel(\"Count\")\n",
    "            ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(directory+'/Calibration Epoch All '+str(e+1)+'.pdf',bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            #Area Under the Curve\n",
    "            fpr, tpr, _= epoch.input_output['roc_curve']\n",
    "\n",
    "            #mehrdad\n",
    "            '''\n",
    "            plt.figure()\n",
    "            lw = 2\n",
    "            #plt.plot(fpr, tpr, color='darkorange',\n",
    "            #     lw=lw, label='ROC curve (area = %0.2f)' % epoch.data['roc_auc'])\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(directory+'/AUC Epoch'+str(e+1)+'.pdf',bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            '''\n",
    "            #mehrdad\n",
    "            '''\n",
    "            plt.figure()\n",
    "            lw = 2\n",
    "            for x in epochsData:        \n",
    "                fpr, tpr, _= x.input_output['roc_curve']\n",
    "                plt.plot(fpr, tpr,\n",
    "                     lw=lw, label='ROC curve Epoch{0} (area = %0.2f)'.format(str(x.number+1)) % x.data['roc_auc'])\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver operating characteristic')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(directory+'/AUC Epochs All'+str(e+1)+'.pdf',bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            '''\n",
    "        \n",
    "    pickleFile=open(directory+'/'+'data{0}.bin'.format(e+1),'wb')\n",
    "    jsonFile=open(directory+'/'+'data{0}.txt'.format(e+1),'wt')\n",
    "    epochFile=open(directory+'/'+'epoch{0}.txt'.format(e+1),'wt')\n",
    "    \n",
    "    model.save(directory+'/'+'model_keras{0}.h5'.format(e+1))\n",
    "\n",
    "\n",
    "    import json\n",
    "    pickle.dump(epoch,pickleFile)\n",
    "    pickleFile.flush()\n",
    "    pickleFile.close()\n",
    "\n",
    "    epochFile.write(str(epoch.number))\n",
    "    epochFile.write(str(epoch.data))\n",
    "    epochFile.write(str(epoch.input_output))\n",
    "    epochFile.close()\n",
    "\n",
    "    jsonFile.write(jsonpickle.encode(epoch))        \n",
    "    #json.dump([epoch.number,epoch.data, epoch.input_output],jsonFile)\n",
    "    jsonFile.flush()\n",
    "    jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.array(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.array(X)[0][29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
